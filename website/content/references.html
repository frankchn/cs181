<h3>References</h3>

<h4>Background about the problems facing higher education and the MOOC revolution</h4>

<p>These sources describe the current problems facing higher education and give a background on factors in support of or criticizing Massively Open Online Courses (MOOCs) and blended learning models.</p>

<p><strong>"Measuring Up 2008 - The National Report Card on Higher Education". National Center for Public Policy and Higher Education, 2008. </strong></p>

<blockquote>"Measuring Up 2008 - The National Report Card on Higher Education" is the 2008 (and latest) edition of an annual series of studies and evaluations of the progress being made in post-secondary education at a National and also at a state level. This resource provides concrete quantitative indicators and international comparisons of the scale and severity of the various problems in America's higher education such as (but not limited to), low college completion rates (18%), low proportion of eligible college-aged students attending degree programs (34%, below that of Hungary) as well as the escalating cost of higher education (increase of 439% over 20 years). This is an important source in establishing that there is a pressing need for innovative solutions (such as MOOCs) to resolve issues of cost and access in higher education today.</blockquote>

<p><strong>T. Friedman. "Revolution Hits the Universities.". The New York Times, January 26 2013. </strong></p>

<blockquote>A follow up from Thomas Friedman for his original op-ed in May 2012 covering the new phenomena of Massively Open Online Courses (MOOCs). This op-ed covers anecdotes and interviews with instructors and major MOOC providers (Coursera and EdX). This source is a progress report of sorts, describing specific examples of how MOOCs have fulfilled some of the promise Friedman predicted in his op-ed just a year prior. The op-ed describes how MOOCs are revolutionizing access to quality education for non-conventional students (e.g. "Daniel", an avid Coursera student) and how classroom interaction can remain rich and enriching even while adopting a MOOC format.</blockquote>

<p><strong>"Evaluation of Evidence-Based Practices in Online Learning: A Meta-Analysis and Review of Online Learning Studies". U.S. Department of Education, September 2010.</strong></p>

<blockquote>This study by the U.S. Department of Education is an authoritative meta-analysis of more than a thousand studies on online education. This is an important study since it specifically targets quantitative studies which compared classroom/face-to-face instruction with online instruction with measurable metrics of student outcome. This is an important source as it demonstrates that across a large number of academic studies, it has been shown that online learning "perform(s) modestly better" than face-to-face instruction and that a blended learning model enhances the improvements observed in online courses vs face-to-face instruction.</blockquote>

<p><strong>C. Thomas. "The Blended Learning Toolkit: Improving Student Performance and Retention". Educause Review, December 15 2011.</strong></p>

<blockquote>A follow-up study inspired by the meta-study above, this source describes an attempt at building an open-access blended learning educational resource - the Blended Learning Toolkit. This source is a supplement to the source before, providing specific data on an analysis of blended learning experiments done at University of Central California (UCF). It is shown that in agreement with the U.S. Department of Education study, a blended classroom setting delivered the best educational outcomes among the paradigms surveyed.</blockquote>

<p><strong>H. Amna. "San Jose State Professors Criticize edX as â€˜Social Injustice'." The Harvard Crimson, May 03 2013.</strong></p>

<blockquote>This is a source criticizing the recent San Jose State University (SJSU) embracing of MOOCs and blended learning. While SJSU has been one of the most proactive institutions in adopting new online learning and especially MOOC style content (having partnered with not one but two major MOOC providers). This source illustrates many of the concerns which critics have expressed about MOOCs and blended learning. The first being primarily a loss of academic freedom as epitomized by how SJSU's president had pressured its dean of Humanities of Arts to adopt EdX's JusticeX course. The second being a worry that MOOCs present an existential threat for faculty at non-top tier institutions as expressed by Prof. Brown (an SJSU associate Philosophy Professor): "That is exactly the fear that we expressed. Eventually, you will only have facilitators for those courses. There will be no need for professors or even graduate students,".</blockquote>

<h4>Specific Problem Areas</h4>

<p>A big focus of our project is to evaluate the efficacy of MOOCs in higher education. As part of this we have identified 2 main areas of contention to focus on:</p>

<ol>
	<li>Effectiveness and accuracy of peer grading systems</li>
	<li>Efficiency and accuracy of automated grading of essays or short answer</li>
</ol>

<p>The following sources are sources relating to these issues which we hope to cover in our project.</p>

<p><strong>C. Kulkarni, K. Pang-Wei, H. Le, D. Chia, K. Papadopoulos, D. Koller, and S. R. Klemmer. "Scaling self and peer assessment to the global design classroom." CHI'13 (to appear), 2013.</strong></p>

<blockquote>A study done on the one of the first applications of calibrated peer grading on a MOOC (Stanford's Human-Computer Interaction MOOC). This paper provides important quantitative validation of peer grading for complex assignments at a scale of tens of thousands of students. It also provides quantitative measures of the reliability of peer grading in a MOOC setting.</blockquote>

<p><strong>C. Piech, J. Huang, Z. Chen, C. Do, A. Ng, and D. Koller, Tuned Models of Peer Assessment in MOOCs. "Tuned Models of Peer Assessment in MOOCs" EDM'13 (to appear), 2013.</strong></p>

<blockquote>A study done on potential improvements of the currently MOOC peer grading system using a probabilistic graphical model approach. This source provides additional quantitative evaluations of the agreement between peer grades (as computed by a sophisticated graphical model based approach) and expert staff grades and demonstrates that good agreement can be obtained with relatively few peer evaluations. This shows the potential of peer grading systems to scale successfully to large groups of students and still provide comparable feedback to students as compared to TAs in conventional courses.</blockquote>

<p><strong>P. Sadler, E. Good. "The Impact of Self- and Peer-Grading on Student Learning". Educational Assessment, 2006. </strong></p>

<blockquote>An older study showing the benefit of peer grading in addition to the ability to scale to large student to instructor ratios. This study shows that there is a pedagogical benefit to peer grading and suggest that improved educational outcomes may result from peer/self-grading systems. This source provides some motivation for considering peer-grading systems even in blended classroom settings where student:teacher ratios may be low enough to permit conventional grading.</blockquote>

<p><strong>J. Markov. "Essay-Grading Software Offers Professors a Break". New York Times, April 04 2013.</strong></p>

<blockquote>A source describing the move by EdX, a major MOOC provider to use automated essay grading as an alternative to expert grading of essays and free-text responses. This source gives a good overview of the various pros and cons of essay autograding and provides a good representation of both the proponents for and critics of automated essay grading. </blockquote>

<p><strong>R. Haswell and M. Wilson. "Professionals Against Machine Scoring Of Student Essays In High-Stakes Assessment". March 12 2013.</strong></p>

<blockquote>An open letter in direct response to the EdX announcement regarding essay autograding. The open letter, which was famously endorsed by Noam Chomsky himself, enumerates several essential weaknesses of essay autograding including but not limited to being easily fooled, being "reductive" and "inaccurate" and being "unfair" and "undiagnostic". This is an important source in establishing that there are serious doubts about the feasibility of essay autograding despite adoption for standardized testing such as the SATs or the GREs.</blockquote>